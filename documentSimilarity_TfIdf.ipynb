{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.ipynb_checkpoints', 'BankTweets.csv', 'BankTweets_04242020.csv', 'BankTweets_04252020.csv', 'BankTweets_04262020.csv', 'BankTweets_04292020.csv', 'cbikkanur_twitter_credentials.ipynb', 'cbikkanur_twitter_credentials.json', 'CosineSimilarity.ipynb', 'documentSimilarity.ipynb', 'documentSimilarity_TfIdf.ipynb', 'documentSimilarity_TfIdf.ipynb.txt', 'getTwitterData.ipynb', 'getTwitterData_TweePy.ipynb', 'model_save', 'SearchTweets.csv', 'SearchTweets_04242020.csv', 'SearchTweets_04252020.csv', 'SearchTweets_04262020.csv', 'SearchTweets_04292020.csv', 'test_vectors.npy', 'TfIdf_similar_test_tweets.csv', 'train_vectors.npy', 'tweets_04232020.csv', 'tweets_04242020.csv', 'tweets_04252020.csv', 'tweets_04262020.csv', 'tweets_04292020.csv']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import os\n",
    "print(os.listdir(\".\"))\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.pipeline import Pipeline\n",
    "np.random.seed(0)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet_Id</th>\n",
       "      <th>User_Id</th>\n",
       "      <th>User_Name</th>\n",
       "      <th>User_Screen_Name</th>\n",
       "      <th>Theme</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1253375593271394312</td>\n",
       "      <td>80374332</td>\n",
       "      <td>Citibank</td>\n",
       "      <td>Citibank</td>\n",
       "      <td>Bank/Financial</td>\n",
       "      <td>Registering for online access and activating y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1253322747851296768</td>\n",
       "      <td>80374332</td>\n",
       "      <td>Citibank</td>\n",
       "      <td>Citibank</td>\n",
       "      <td>Bank/Financial</td>\n",
       "      <td>Protect your CARES Act payments: Validate comm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1253066045700681731</td>\n",
       "      <td>80374332</td>\n",
       "      <td>Citibank</td>\n",
       "      <td>Citibank</td>\n",
       "      <td>Bank/Financial</td>\n",
       "      <td>It’s simple to set up a payment account in the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1252960358454767616</td>\n",
       "      <td>80374332</td>\n",
       "      <td>Citibank</td>\n",
       "      <td>Citibank</td>\n",
       "      <td>Bank/Financial</td>\n",
       "      <td>We’re committed to helping provide the support...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1252673469852143618</td>\n",
       "      <td>80374332</td>\n",
       "      <td>Citibank</td>\n",
       "      <td>Citibank</td>\n",
       "      <td>Bank/Financial</td>\n",
       "      <td>Protect Yourself from COVID-19 Scams: Don’t re...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Tweet_Id   User_Id User_Name User_Screen_Name           Theme  \\\n",
       "0  1253375593271394312  80374332  Citibank         Citibank  Bank/Financial   \n",
       "1  1253322747851296768  80374332  Citibank         Citibank  Bank/Financial   \n",
       "2  1253066045700681731  80374332  Citibank         Citibank  Bank/Financial   \n",
       "3  1252960358454767616  80374332  Citibank         Citibank  Bank/Financial   \n",
       "4  1252673469852143618  80374332  Citibank         Citibank  Bank/Financial   \n",
       "\n",
       "                                                Text  \n",
       "0  Registering for online access and activating y...  \n",
       "1  Protect your CARES Act payments: Validate comm...  \n",
       "2  It’s simple to set up a payment account in the...  \n",
       "3  We’re committed to helping provide the support...  \n",
       "4  Protect Yourself from COVID-19 Scams: Don’t re...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_files = ['./tweets_04232020.csv', './tweets_04242020.csv', './tweets_04252020.csv', './tweets_04262020.csv', './tweets_04292020.csv']\n",
    "\n",
    "df_list = []\n",
    "for filename in all_files:\n",
    "    df_list.append(pd.read_csv(filename, sep=',',header=0, encoding='utf-8', index_col = 0))\n",
    "    \n",
    "df_tweets = pd.concat(df_list, ignore_index=True)\n",
    "df_tweets.head()     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7958, 6)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets.drop_duplicates([\"Text\", \"User_Id\"], inplace=True) # remove duplicates in place and reset index\n",
    "df_tweets = df_tweets.reset_index(drop=True)\n",
    "df_tweets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7953</th>\n",
       "      <td>RT @lucxs__x: You're the coffee that I need in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7954</th>\n",
       "      <td>RT @RoberteLove: I had to go to the store this...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7955</th>\n",
       "      <td>@mykalmphoto Nice photos.  When this is all ov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7956</th>\n",
       "      <td>RT @minturnalexandr: Ten years ago I bought th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7957</th>\n",
       "      <td>RT @IvankaTrump: Small businesses like Amy Wri...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text\n",
       "7953  RT @lucxs__x: You're the coffee that I need in...\n",
       "7954  RT @RoberteLove: I had to go to the store this...\n",
       "7955  @mykalmphoto Nice photos.  When this is all ov...\n",
       "7956  RT @minturnalexandr: Ten years ago I bought th...\n",
       "7957  RT @IvankaTrump: Small businesses like Amy Wri..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "df['text'] = df_tweets['Text']\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total records: 7958 \n",
      "Train records: 6366 \n",
      " Test records: 1592\n"
     ]
    }
   ],
   "source": [
    "total_indices_size = df.shape[0]\n",
    "train_size = 0.8\n",
    "train_indices_size = int(train_size * total_indices_size)\n",
    "test_indices_size = total_indices_size - train_indices_size\n",
    "print('Total records: {} \\nTrain records: {} \\n Test records: {}'.format(total_indices_size, train_indices_size, test_indices_size))\n",
    "\n",
    "total_indices_array = np.array([x for x in range(total_indices_size)])\n",
    "np.random.shuffle(total_indices_array)\n",
    "train_indices, test_indices = total_indices_array[:train_indices_size], total_indices_array[train_indices_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6366, 1) (1592, 1)\n"
     ]
    }
   ],
   "source": [
    "train_set, test_set = df.loc[train_indices], df.loc[test_indices]\n",
    "print(train_set.shape, test_set.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CountVectorizer & Tf-Idf:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer(stop_words = 'english', ngram_range=(1,3), \\\n",
    "                                   strip_accents='unicode', \\\n",
    "                                   analyzer = 'word',lowercase = True)\n",
    "tfidf = TfidfTransformer()\n",
    "pipeline = Pipeline(steps=[('count_vectorizer', count_vectorizer), ('tfidf', tfidf)])\n",
    "\n",
    "tf_idf_train_matrix = pipeline.fit_transform(train_set[\"text\"])\n",
    "tf_idf_test_matrix = pipeline.transform(test_set[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Matrix Shape: (6366, 120508)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Matrix Shape:\", tf_idf_train_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_similar_texts(query_text, query_text_vector,  train_matrix, train_indices, df_tweets, n = 5):\n",
    "    cosine_similarities_n = cosine_similarity(query_text_vector, train_matrix).flatten()\n",
    "    top_Indices = cosine_similarities_n.argsort()[::-1][:n]\n",
    "    top_tweet_Indices = train_indices[top_Indices]\n",
    "    \n",
    "    print('\\nInput Text:\\n {} \\n'.format(query_text))\n",
    "    for index, sim_text in enumerate(df_tweets.loc[top_tweet_Indices, \"Text\"]):\n",
    "        print('=' * 30, 'Similar Text: {} || Similar Score: {}'.format(index+1, np.round(cosine_similarities_n[top_Indices[index]], 3)), '=' * 30, '\\n')\n",
    "        print(sim_text, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Input Text:\n",
      " @xoxjessiica I am sorry to hear this. It should appear on the next or following statement. To forward to our internal team on your behalf, DM account/card type only, full name and contact phone number already on profile. No PIN or account numbers. ^Deanna https://t.co/gvC4jAOA9c \n",
      "\n",
      "============================== Similar Text: 1 || Similar Score: 0.387 ============================== \n",
      "\n",
      "@conorFa16113956 We suggest deleting the previous public tweet and DM the full name, and contact phone number only that is already on profile. Email and Twitter are not secure banking communication channels. Do not DM any PIN or account numbers. ^Deanna https://t.co/gvC4jAOA9c \n",
      "\n",
      "============================== Similar Text: 2 || Similar Score: 0.345 ============================== \n",
      "\n",
      "@this_is_Manu Thanks for reaching out. We are here to help. Let us review this further. DM the account/card type only (checking, credit card, retail branded store card, etc) and country where it was open. Do not reply with any PIN or account numbers. ^Deanna https://t.co/gvC4jAOA9c \n",
      "\n",
      "============================== Similar Text: 3 || Similar Score: 0.338 ============================== \n",
      "\n",
      "@FlyinGaurav Due to COVID-19 impact causing higher volumes worldwide, please DM the concerns, account/card type only, and the country where it was open. Do not reply with any PIN or account numbers. ^Deanna https://t.co/gvC4jAOA9c \n",
      "\n",
      "============================== Similar Text: 4 || Similar Score: 0.317 ============================== \n",
      "\n",
      "@N66756195 We are here to help. Let us review this further. Please DM the details of your inquiry, account card type only, and country where it was open. Do not reply with any PIN or account numbers. ^Deanna https://t.co/gvC4jB6b0K \n",
      "\n",
      "============================== Similar Text: 5 || Similar Score: 0.292 ============================== \n",
      "\n",
      "@amri_anand Just following up since no response found. Feel free to DM us the details, account/card type, and country account was opened in if further help is needed. No PIN or account numbers. ^Deanna \n",
      "\n"
     ]
    }
   ],
   "source": [
    "query_index = 5\n",
    "query_text = df_tweets.loc[test_indices[query_index], \"Text\"]\n",
    "query_text_vector = tf_idf_test_matrix[query_index]\n",
    "print_similar_texts(query_text, query_text_vector, tf_idf_train_matrix, train_indices, df_tweets, n = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_similar_n(tf_idf_train_matrix, train_indices, tf_idf_test_matrix, test_indices, test_set_df, df_tweets, n=5):\n",
    "    similar_texts_list = []\n",
    "    similar_scores_list = []\n",
    "    similar_top_score_list = []\n",
    "    similar_themes_list = []\n",
    "    similar_top_themes_list = []\n",
    "    for vector in tf_idf_test_matrix:\n",
    "        cosine_similarities_n = cosine_similarity(vector, tf_idf_train_matrix).flatten()\n",
    "        similar_doc_indices =  cosine_similarities_n.argsort()[::-1][:n]\n",
    "        top_tweet_Indices = train_indices[similar_doc_indices]\n",
    "        \n",
    "        similar_texts = [text for text in df_tweets.loc[top_tweet_Indices, \"Text\"]]\n",
    "        similar_texts_list.append(similar_texts)\n",
    "        \n",
    "        similar_scores = [np.round(score, 3) for score in cosine_similarities_n[similar_doc_indices]]\n",
    "        similar_scores_list.append(similar_scores)\n",
    "        similar_top_score_list.append(similar_scores[0])\n",
    "                                                                   \n",
    "        similar_themes = [theme for theme in df_tweets.loc[top_tweet_Indices, \"Theme\"]]\n",
    "        similar_themes_list.append(similar_themes)\n",
    "        \n",
    "        top_similar_theme = max(set(similar_themes), key=lambda x: similar_themes.count(x))\n",
    "        similar_top_themes_list.append(top_similar_theme)\n",
    "    \n",
    "    df = test_set_df \n",
    "    df[\"original_theme\"] = df_tweets.loc[test_indices, \"Theme\"]\n",
    "    df[\"similar_texts\"] = similar_texts_list\n",
    "    df[\"similar_scores\"] = similar_scores_list  \n",
    "    df[\"top_similar_score\"] = similar_top_score_list\n",
    "    df[\"similar_themes\"] = similar_themes_list\n",
    "    df[\"top_similar_themes\"] = similar_top_themes_list\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>original_theme</th>\n",
       "      <th>similar_texts</th>\n",
       "      <th>similar_scores</th>\n",
       "      <th>top_similar_score</th>\n",
       "      <th>similar_themes</th>\n",
       "      <th>top_similar_themes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6953</th>\n",
       "      <td>RT @Essence: Join us TOMORROW, 4/27 at 7 PM ES...</td>\n",
       "      <td>Bank/Financial</td>\n",
       "      <td>[Good Night Everyone. We will return promptly ...</td>\n",
       "      <td>[0.122, 0.116, 0.086, 0.082, 0.077, 0.075, 0.0...</td>\n",
       "      <td>0.122</td>\n",
       "      <td>[Bank/Financial, Bank/Financial, coffee, car, ...</td>\n",
       "      <td>Bank/Financial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6031</th>\n",
       "      <td>RT @Jordan_Sather_: I can (almost) guarantee y...</td>\n",
       "      <td>nasa</td>\n",
       "      <td>[RT @Jordan_Sather_: I can (almost) guarantee ...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 0.043, 0.041, 0.039,...</td>\n",
       "      <td>1.000</td>\n",
       "      <td>[nasa, nasa, nasa, nasa, nasa, nasa, nasa, nas...</td>\n",
       "      <td>nasa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>@roth_jroth1515 Hi Jennifer. Do you have a mom...</td>\n",
       "      <td>Bank/Financial</td>\n",
       "      <td>[@roth_jroth1515 hi Jennifer, sorry to hear th...</td>\n",
       "      <td>[0.391, 0.306, 0.155, 0.149, 0.145, 0.139, 0.1...</td>\n",
       "      <td>0.391</td>\n",
       "      <td>[Bank/Financial, Bank/Financial, Bank/Financia...</td>\n",
       "      <td>Bank/Financial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5720</th>\n",
       "      <td>RT @gguksluver: jimins face when he realized j...</td>\n",
       "      <td>cake</td>\n",
       "      <td>[RT @gguksluver: jimins face when he realized ...</td>\n",
       "      <td>[1.0, 1.0, 0.058, 0.055, 0.05, 0.05, 0.049, 0....</td>\n",
       "      <td>1.000</td>\n",
       "      <td>[cake, cake, cake, cake, cake, cake, cake, cak...</td>\n",
       "      <td>cake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7102</th>\n",
       "      <td>RT @SaralPatel: Shri @RahulGandhi will be inte...</td>\n",
       "      <td>covid-19</td>\n",
       "      <td>[RT @srinivasiyc: Shri @RahulGandhi will be in...</td>\n",
       "      <td>[0.917, 0.904, 0.904, 0.058, 0.039, 0.035, 0.0...</td>\n",
       "      <td>0.917</td>\n",
       "      <td>[covid-19, covid-19, covid-19, covid-19, covid...</td>\n",
       "      <td>covid-19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  original_theme  \\\n",
       "6953  RT @Essence: Join us TOMORROW, 4/27 at 7 PM ES...  Bank/Financial   \n",
       "6031  RT @Jordan_Sather_: I can (almost) guarantee y...            nasa   \n",
       "239   @roth_jroth1515 Hi Jennifer. Do you have a mom...  Bank/Financial   \n",
       "5720  RT @gguksluver: jimins face when he realized j...            cake   \n",
       "7102  RT @SaralPatel: Shri @RahulGandhi will be inte...        covid-19   \n",
       "\n",
       "                                          similar_texts  \\\n",
       "6953  [Good Night Everyone. We will return promptly ...   \n",
       "6031  [RT @Jordan_Sather_: I can (almost) guarantee ...   \n",
       "239   [@roth_jroth1515 hi Jennifer, sorry to hear th...   \n",
       "5720  [RT @gguksluver: jimins face when he realized ...   \n",
       "7102  [RT @srinivasiyc: Shri @RahulGandhi will be in...   \n",
       "\n",
       "                                         similar_scores  top_similar_score  \\\n",
       "6953  [0.122, 0.116, 0.086, 0.082, 0.077, 0.075, 0.0...              0.122   \n",
       "6031  [1.0, 1.0, 1.0, 1.0, 1.0, 0.043, 0.041, 0.039,...              1.000   \n",
       "239   [0.391, 0.306, 0.155, 0.149, 0.145, 0.139, 0.1...              0.391   \n",
       "5720  [1.0, 1.0, 0.058, 0.055, 0.05, 0.05, 0.049, 0....              1.000   \n",
       "7102  [0.917, 0.904, 0.904, 0.058, 0.039, 0.035, 0.0...              0.917   \n",
       "\n",
       "                                         similar_themes top_similar_themes  \n",
       "6953  [Bank/Financial, Bank/Financial, coffee, car, ...     Bank/Financial  \n",
       "6031  [nasa, nasa, nasa, nasa, nasa, nasa, nasa, nas...               nasa  \n",
       "239   [Bank/Financial, Bank/Financial, Bank/Financia...     Bank/Financial  \n",
       "5720  [cake, cake, cake, cake, cake, cake, cake, cak...               cake  \n",
       "7102  [covid-19, covid-19, covid-19, covid-19, covid...           covid-19  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similar_test_df = find_similar_n(tf_idf_train_matrix, train_indices, tf_idf_test_matrix, test_indices, test_set, df_tweets, n=10)\n",
    "similar_test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test data in predicting theme: 82.1%\n"
     ]
    }
   ],
   "source": [
    "accuracy = 100 * np.sum(similar_test_df[\"original_theme\"] == similar_test_df[\"top_similar_themes\"])/similar_test_df.shape[0]\n",
    "print(\"Accuracy on test data in predicting theme: {}%\".format(np.round(accuracy,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_test_df.to_csv(\"TfIdf_similar_test_tweets.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
