{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "documentSimilarity_BERT.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMsI63IwtvOtEsRXxA+LxDj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cbikkanur/twitter/blob/master/documentSimilarity_BERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HN2uyOrhG9i8",
        "colab_type": "code",
        "outputId": "84822328-16d8-4a3e-8400-89ff2f5cf44f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import csv\n",
        "import os\n",
        "import time\n",
        "import datetime\n",
        "print(os.listdir(\".\"))\n",
        "from scipy.spatial import distance\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.pipeline import Pipeline\n",
        "np.random.seed(0)\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['.config', 'drive', 'test_vectors.npy', 'BERT_similar_test_tweets.csv', 'similar_test_tweets.csv', 'BERT_nearest_test_tweets.csv', 'train_vectors.npy', 'sample_data']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5gRJ2QCg8eG",
        "colab_type": "code",
        "outputId": "f1b7de13-f72f-4a1b-ad87-b4740a77e4d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "# Go to Edit > Notebook Settings > Hardware accelerator > GPU\n",
        "device_name = tf.test.gpu_device_name()\n",
        "print(device_name)\n",
        "\n",
        "import torch\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device('cuda')\n",
        "  print('We will use {} {}GPU(s)'.format(torch.cuda.device_count(), torch.cuda.get_device_name() ))\n",
        "else:\n",
        "  device = torch.device('cuda')\n",
        "  print('No GPU(s) available; we will use \"cpu\"')\n",
        "\n",
        "device=torch.device('cuda')"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/device:GPU:0\n",
            "We will use 1 Tesla P100-PCIE-16GBGPU(s)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Nau6J3cII9B",
        "colab_type": "code",
        "outputId": "824e748b-aa61-4d3f-e820-719e35f4cf7a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Run this cell to mount your Google Drive.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3L9M0ACxIwYX",
        "colab_type": "code",
        "outputId": "e7f05b3b-ed7d-4949-9233-281a93d96fe0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "DRIVE_PATH = \"/content/drive/My Drive/MIDS/docSimilarity/\"\n",
        "\n",
        "print(os.listdir(DRIVE_PATH))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['CosineSimilarity.ipynb', 'getTwitterData_TweePy.ipynb', 'cbikkanur_twitter_credentials.json', 'cbikkanur_twitter_credentials.ipynb', 'tweets_04232020.csv', 'SearchTweets.csv', 'BankTweets.csv', 'documentSimilarity.ipynb', 'tweets_04242020.csv', 'SearchTweets_04242020.csv', 'BankTweets_04242020.csv', 'SearchTweets_04252020.csv', 'tweets_04252020.csv', 'BankTweets_04252020.csv', 'documentSimilarity_TfIdf.ipynb.txt', 'SearchTweets_04262020.csv', 'BankTweets_04262020.csv', 'tweets_04262020.csv', '.ipynb_checkpoints', 'model_save', 'train_vectors.npy', 'test_vectors.npy', 'getTwitterData.ipynb', 'SearchTweets_04292020.csv', 'BankTweets_04292020.csv', 'tweets_04292020.csv', 'TfIdf_similar_test_tweets.csv', 'documentSimilarity_TfIdf.ipynb']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yF_J22-1I-RR",
        "colab_type": "code",
        "outputId": "f8c23741-89e8-467f-8e08-9c90e854ac56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "all_files = [DRIVE_PATH+'tweets_04232020.csv', DRIVE_PATH+'./tweets_04242020.csv', DRIVE_PATH+'./tweets_04252020.csv', DRIVE_PATH+'./tweets_04262020.csv', DRIVE_PATH+'./tweets_04292020.csv']\n",
        "\n",
        "df_list = []\n",
        "for filename in all_files:\n",
        "    df_list.append(pd.read_csv(filename, sep=',',header=0, encoding='utf-8', index_col = 0))\n",
        "    \n",
        "df_tweets = pd.concat(df_list, ignore_index=True)\n",
        "df_tweets    "
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tweet_Id</th>\n",
              "      <th>User_Id</th>\n",
              "      <th>User_Name</th>\n",
              "      <th>User_Screen_Name</th>\n",
              "      <th>Theme</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1253375593271394312</td>\n",
              "      <td>80374332</td>\n",
              "      <td>Citibank</td>\n",
              "      <td>Citibank</td>\n",
              "      <td>Bank/Financial</td>\n",
              "      <td>Registering for online access and activating y...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1253322747851296768</td>\n",
              "      <td>80374332</td>\n",
              "      <td>Citibank</td>\n",
              "      <td>Citibank</td>\n",
              "      <td>Bank/Financial</td>\n",
              "      <td>Protect your CARES Act payments: Validate comm...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1253066045700681731</td>\n",
              "      <td>80374332</td>\n",
              "      <td>Citibank</td>\n",
              "      <td>Citibank</td>\n",
              "      <td>Bank/Financial</td>\n",
              "      <td>It’s simple to set up a payment account in the...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1252960358454767616</td>\n",
              "      <td>80374332</td>\n",
              "      <td>Citibank</td>\n",
              "      <td>Citibank</td>\n",
              "      <td>Bank/Financial</td>\n",
              "      <td>We’re committed to helping provide the support...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1252673469852143618</td>\n",
              "      <td>80374332</td>\n",
              "      <td>Citibank</td>\n",
              "      <td>Citibank</td>\n",
              "      <td>Bank/Financial</td>\n",
              "      <td>Protect Yourself from COVID-19 Scams: Don’t re...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14995</th>\n",
              "      <td>1255520212260175872</td>\n",
              "      <td>1051372512582328321</td>\n",
              "      <td>vinlywrongar</td>\n",
              "      <td>vinlywrongar</td>\n",
              "      <td>coffee</td>\n",
              "      <td>RT @lucxs__x: You're the coffee that I need in...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14996</th>\n",
              "      <td>1255520211610075136</td>\n",
              "      <td>16383553</td>\n",
              "      <td>janmaxwell</td>\n",
              "      <td>janmaxwell</td>\n",
              "      <td>coffee</td>\n",
              "      <td>RT @RoberteLove: I had to go to the store this...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14997</th>\n",
              "      <td>1255520210041348096</td>\n",
              "      <td>547284373</td>\n",
              "      <td>Beth Ann Cook</td>\n",
              "      <td>revbethanncook</td>\n",
              "      <td>coffee</td>\n",
              "      <td>@mykalmphoto Nice photos.  When this is all ov...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14998</th>\n",
              "      <td>1255520209500323842</td>\n",
              "      <td>355634795</td>\n",
              "      <td>first name crap second name bag</td>\n",
              "      <td>blaairee</td>\n",
              "      <td>coffee</td>\n",
              "      <td>RT @minturnalexandr: Ten years ago I bought th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14999</th>\n",
              "      <td>1255520206711074817</td>\n",
              "      <td>2159921089</td>\n",
              "      <td>NDGirl</td>\n",
              "      <td>NDisGreat</td>\n",
              "      <td>coffee</td>\n",
              "      <td>RT @IvankaTrump: Small businesses like Amy Wri...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>15000 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                  Tweet_Id  ...                                               Text\n",
              "0      1253375593271394312  ...  Registering for online access and activating y...\n",
              "1      1253322747851296768  ...  Protect your CARES Act payments: Validate comm...\n",
              "2      1253066045700681731  ...  It’s simple to set up a payment account in the...\n",
              "3      1252960358454767616  ...  We’re committed to helping provide the support...\n",
              "4      1252673469852143618  ...  Protect Yourself from COVID-19 Scams: Don’t re...\n",
              "...                    ...  ...                                                ...\n",
              "14995  1255520212260175872  ...  RT @lucxs__x: You're the coffee that I need in...\n",
              "14996  1255520211610075136  ...  RT @RoberteLove: I had to go to the store this...\n",
              "14997  1255520210041348096  ...  @mykalmphoto Nice photos.  When this is all ov...\n",
              "14998  1255520209500323842  ...  RT @minturnalexandr: Ten years ago I bought th...\n",
              "14999  1255520206711074817  ...  RT @IvankaTrump: Small businesses like Amy Wri...\n",
              "\n",
              "[15000 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RR3S0KmLJvyA",
        "colab_type": "code",
        "outputId": "a6168adb-b1b3-4d24-e53b-8ddb6e9aaf4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "df_tweets.drop_duplicates([\"Text\", \"User_Id\"], inplace=True) # remove duplicates in place and reset index\n",
        "df_tweets = df_tweets.reset_index(drop=True)\n",
        "df_tweets.shape"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7958, 6)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YodXojYDJ2O8",
        "colab_type": "code",
        "outputId": "b8dc5e7f-273f-4a7e-ea5d-e8d225dd6c00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df = pd.DataFrame()\n",
        "df['text'] = df_tweets['Text']\n",
        "df.tail()"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7953</th>\n",
              "      <td>RT @lucxs__x: You're the coffee that I need in...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7954</th>\n",
              "      <td>RT @RoberteLove: I had to go to the store this...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7955</th>\n",
              "      <td>@mykalmphoto Nice photos.  When this is all ov...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7956</th>\n",
              "      <td>RT @minturnalexandr: Ten years ago I bought th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7957</th>\n",
              "      <td>RT @IvankaTrump: Small businesses like Amy Wri...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   text\n",
              "7953  RT @lucxs__x: You're the coffee that I need in...\n",
              "7954  RT @RoberteLove: I had to go to the store this...\n",
              "7955  @mykalmphoto Nice photos.  When this is all ov...\n",
              "7956  RT @minturnalexandr: Ten years ago I bought th...\n",
              "7957  RT @IvankaTrump: Small businesses like Amy Wri..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S0q6wqLlJ5CS",
        "colab_type": "code",
        "outputId": "32f4507a-e950-4bd9-cf7a-6a752c02a228",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "total_indices_size = df.shape[0]\n",
        "train_size = 0.8\n",
        "train_indices_size = int(train_size * total_indices_size)\n",
        "test_indices_size = total_indices_size - train_indices_size\n",
        "print('total records: {}\\n trainig_set record: {}\\n test_set records: {}'.format(total_indices_size, train_indices_size, test_indices_size))\n",
        "\n",
        "total_indices_array = np.array([x for x in range(total_indices_size)])\n",
        "np.random.shuffle(total_indices_array)\n",
        "train_indices, test_indices = total_indices_array[:train_indices_size], total_indices_array[train_indices_size:]"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total records: 7958\n",
            " trainig_set record: 6366\n",
            " test_set records: 1592\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HelsofoBJ9uD",
        "colab_type": "code",
        "outputId": "12642817-600b-475d-85ca-837196d43914",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "train_set, test_set = df.loc[train_indices], df.loc[test_indices]\n",
        "train_set[:5]"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2459</th>\n",
              "      <td>@ImHerMajesty Get a truck. I want my next car ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7208</th>\n",
              "      <td>(That's a cake using LEGO bricks. Not an actua...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3067</th>\n",
              "      <td>@J_C_Shin Hi thanks for reaching out. It's imp...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5900</th>\n",
              "      <td>RT @LetsWeeb: Why does this dog look like it j...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>274</th>\n",
              "      <td>@theliftsavage Hi. No, this is not something w...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   text\n",
              "2459  @ImHerMajesty Get a truck. I want my next car ...\n",
              "7208  (That's a cake using LEGO bricks. Not an actua...\n",
              "3067  @J_C_Shin Hi thanks for reaching out. It's imp...\n",
              "5900  RT @LetsWeeb: Why does this dog look like it j...\n",
              "274   @theliftsavage Hi. No, this is not something w..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-zYjqYE5KdZn",
        "colab_type": "code",
        "outputId": "6c676f9a-661e-4278-b23e-e80513731758",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "# Documentation for transformers: https://huggingface.co/transformers/index.html\n",
        "! pip install transformers"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (2.8.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.41)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.12.46)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.38.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: tokenizers==0.5.2 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.86)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.5)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
            "Requirement already satisfied: botocore<1.16.0,>=1.15.46 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.15.46)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.4.5.1)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.46->boto3->transformers) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.46->boto3->transformers) (2.8.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3asqvTaZK1Lt",
        "colab_type": "code",
        "outputId": "59451de3-3492-4c21-c4d0-6fff99288f49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import torch\n",
        "from transformers import BertTokenizer, BertModel, BertForSequenceClassification\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', output_hidden_states = True ) # return hidden layers\n",
        "model.cuda"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method Module.cuda of BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ydr44zz0WVOp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def vectorize_sentence(tokenizer, model, text):\n",
        "  MAX_LENGTH = 140\n",
        "  input_ids = tokenizer.encode(text, add_special_tokens=True, max_length=MAX_LENGTH) # encode for tokenizing\n",
        "  padded_sequences = pad_sequences([input_ids], maxlen=MAX_LENGTH, dtype='long', truncating='post', padding='post') # pad 0 at the end of sentence until MAX_LENGTH\n",
        "  input_ids = padded_sequences[0] # remove the outer list\n",
        "  attention_mask = [int(i>0) for i in input_ids]\n",
        "\n",
        "  input_ids = torch.tensor(input_ids)\n",
        "  attention_mask = torch.tensor(attention_mask)\n",
        "\n",
        "  input_ids = input_ids.unsqueeze(0) # Extra dimension for batch\n",
        "  attention_mask = attention_mask.unsqueeze(0)  # Extra dimension for batch\n",
        "\n",
        "  model.eval() # Only forward pass\n",
        "  input_ids.to(device) # https://github.com/huggingface/transformers/blob/master/notebooks/02-transformers.ipynb\n",
        "  attention_mask.to(device)\n",
        "\n",
        "  with torch.no_grad(): # No gradient descent n\n",
        "    logits, encoded_layers = model(input_ids = input_ids, token_type_ids = None, attention_mask = attention_mask)\n",
        "    last_layer = 12\n",
        "    batch = 0\n",
        "    last_token_index = 0 \n",
        "\n",
        "    vector = encoded_layers[last_layer][batch][last_token_index]\n",
        "    vector = vector.detach().cpu().numpy()\n",
        "\n",
        "    return vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gGOR63eKLzwz",
        "colab_type": "code",
        "outputId": "0b65563e-27d7-44b5-b791-4f3d1916dbec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "sample_text = test_set.iloc[2].text\n",
        "sample_tokens = tokenizer.tokenize(sample_text)\n",
        "print('sample text: \\n{} \\n\\n BERT tokens for sample text: \\n{}'.format(sample_text, sample_tokens))"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample text: \n",
            "@roth_jroth1515 Hi Jennifer. Do you have a moment to Live Chat? ^B \n",
            "\n",
            " BERT tokens for sample text: \n",
            "['@', 'roth', '_', 'jr', '##oth', '##15', '##15', 'hi', 'jennifer', '.', 'do', 'you', 'have', 'a', 'moment', 'to', 'live', 'chat', '?', '^', 'b']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VPyFYQPHbYwd",
        "colab_type": "code",
        "outputId": "c79eae77-a977-4b55-b220-0cc9c8588675",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "sample_vector = vectorize_sentence(tokenizer, model, sample_text)\n",
        "print('Shape of the vector: {}'.format(sample_vector.shape))"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of the vector: (768,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ua0wTgbUuDLp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def format_time(elapsed):\n",
        "  return str(datetime.timedelta(seconds = int(round(elapsed))))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SgpEpShXb2rH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def vectorize_dataset(df):\n",
        "  start_time = time.time()\n",
        "  embeddings = []\n",
        "  num_records = df.shape[0]\n",
        "  row_num = 0\n",
        "  for index, row in df.iterrows():\n",
        "    text = row['text']\n",
        "    if row_num % 200 == 0 and not row_num == 0:\n",
        "      elapsed = format_time(time.time() - start_time)\n",
        "      rows_per_sec = (time.time() - start_time) / row_num\n",
        "      remaining_sec = rows_per_sec * (num_records - row_num)\n",
        "      remaining = format_time(remaining_sec)\n",
        "      print(' comment {:>7,} of {:>7,}.    Elapsed: {:}. Remaining: {:}'.format(row_num, num_records, elapsed, remaining))\n",
        "    embeddings.append(vectorize_sentence(tokenizer, model, text))\n",
        "    row_num += 1\n",
        "  return  embeddings "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHdmBeGbk91K",
        "colab_type": "code",
        "outputId": "a538219f-301e-4c48-bfd9-c6c16aabe3b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        }
      },
      "source": [
        "\n",
        "train_set_embeddings = vectorize_dataset(train_set)\n",
        "train_vectors = np.stack(train_set_embeddings)\n",
        "train_vectors.shape"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " comment     200 of   6,366.    Elapsed: 0:01:35. Remaining: 0:48:39\n",
            " comment     400 of   6,366.    Elapsed: 0:03:09. Remaining: 0:47:03\n",
            " comment     600 of   6,366.    Elapsed: 0:04:44. Remaining: 0:45:24\n",
            " comment     800 of   6,366.    Elapsed: 0:06:17. Remaining: 0:43:45\n",
            " comment   1,000 of   6,366.    Elapsed: 0:07:49. Remaining: 0:41:55\n",
            " comment   1,200 of   6,366.    Elapsed: 0:09:19. Remaining: 0:40:08\n",
            " comment   1,400 of   6,366.    Elapsed: 0:10:50. Remaining: 0:38:27\n",
            " comment   1,600 of   6,366.    Elapsed: 0:12:20. Remaining: 0:36:44\n",
            " comment   1,800 of   6,366.    Elapsed: 0:13:51. Remaining: 0:35:08\n",
            " comment   2,000 of   6,366.    Elapsed: 0:15:23. Remaining: 0:33:34\n",
            " comment   2,200 of   6,366.    Elapsed: 0:16:56. Remaining: 0:32:03\n",
            " comment   2,400 of   6,366.    Elapsed: 0:18:28. Remaining: 0:30:31\n",
            " comment   2,600 of   6,366.    Elapsed: 0:20:02. Remaining: 0:29:00\n",
            " comment   2,800 of   6,366.    Elapsed: 0:21:35. Remaining: 0:27:30\n",
            " comment   3,000 of   6,366.    Elapsed: 0:23:10. Remaining: 0:25:59\n",
            " comment   3,200 of   6,366.    Elapsed: 0:24:44. Remaining: 0:24:29\n",
            " comment   3,400 of   6,366.    Elapsed: 0:26:21. Remaining: 0:22:59\n",
            " comment   3,600 of   6,366.    Elapsed: 0:27:56. Remaining: 0:21:27\n",
            " comment   3,800 of   6,366.    Elapsed: 0:29:31. Remaining: 0:19:56\n",
            " comment   4,000 of   6,366.    Elapsed: 0:31:06. Remaining: 0:18:24\n",
            " comment   4,200 of   6,366.    Elapsed: 0:32:40. Remaining: 0:16:51\n",
            " comment   4,400 of   6,366.    Elapsed: 0:34:15. Remaining: 0:15:18\n",
            " comment   4,600 of   6,366.    Elapsed: 0:35:53. Remaining: 0:13:47\n",
            " comment   4,800 of   6,366.    Elapsed: 0:37:30. Remaining: 0:12:14\n",
            " comment   5,000 of   6,366.    Elapsed: 0:39:05. Remaining: 0:10:41\n",
            " comment   5,200 of   6,366.    Elapsed: 0:40:42. Remaining: 0:09:08\n",
            " comment   5,400 of   6,366.    Elapsed: 0:42:22. Remaining: 0:07:35\n",
            " comment   5,600 of   6,366.    Elapsed: 0:44:01. Remaining: 0:06:01\n",
            " comment   5,800 of   6,366.    Elapsed: 0:45:38. Remaining: 0:04:27\n",
            " comment   6,000 of   6,366.    Elapsed: 0:47:14. Remaining: 0:02:53\n",
            " comment   6,200 of   6,366.    Elapsed: 0:48:48. Remaining: 0:01:18\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6366, 768)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vT5M5WZbko7F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "293a0221-b9a8-4072-de9e-8688adff5f19"
      },
      "source": [
        "test_set_embeddings = vectorize_dataset(test_set)\n",
        "test_vectors = np.stack(test_set_embeddings)\n",
        "test_vectors.shape\n"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " comment     200 of   1,592.    Elapsed: 0:01:34. Remaining: 0:10:55\n",
            " comment     400 of   1,592.    Elapsed: 0:03:09. Remaining: 0:09:22\n",
            " comment     600 of   1,592.    Elapsed: 0:04:44. Remaining: 0:07:49\n",
            " comment     800 of   1,592.    Elapsed: 0:06:19. Remaining: 0:06:15\n",
            " comment   1,000 of   1,592.    Elapsed: 0:07:54. Remaining: 0:04:40\n",
            " comment   1,200 of   1,592.    Elapsed: 0:09:29. Remaining: 0:03:06\n",
            " comment   1,400 of   1,592.    Elapsed: 0:11:04. Remaining: 0:01:31\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1592, 768)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pkpQ5CKllMoJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ee0ae07a-20a4-4d56-f6ba-b9b178301722"
      },
      "source": [
        "output_dir = './drive/My Drive/MIDS/docSimilarity/model_save/'\n",
        "print(os.listdir(\".\"))\n",
        "if not os.path.exists(output_dir):\n",
        "  print('directory does not exist')\n",
        "  os.makedirs(output_dir)\n",
        "\n",
        "np.save('train_vectors.npy', train_vectors)  \n",
        "np.save('test_vectors.npy', test_vectors)  \n",
        "\n",
        "! cp -r ./train_vectors.npy './drive/My Drive/MIDS/docSimilarity/model_save/'\n",
        "! cp -r ./test_vectors.npy './drive/My Drive/MIDS/docSimilarity/model_save/'"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['.config', 'drive', 'test_vectors.npy', 'similar_test_tweets.csv', 'BERT_nearest_test_tweets.csv', 'train_vectors.npy', 'sample_data']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tgA1G9HqV3ok",
        "colab_type": "text"
      },
      "source": [
        "# Cosine Similarity:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ttF6eVxJugqj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def print_similar_texts(query_text, query_text_vector,  train_matrix, train_indices, df_tweets, n = 5):\n",
        "    cosine_similarities_n = cosine_similarity(query_text_vector, train_matrix).flatten()\n",
        "    top_Indices = cosine_similarities_n.argsort()[::-1][:n]\n",
        "    top_tweet_Indices = train_indices[top_Indices]\n",
        "    \n",
        "    print('\\nInput Text:\\n {} \\n'.format(query_text))\n",
        "    for index, sim_text in enumerate(df_tweets.loc[top_tweet_Indices, \"Text\"]):\n",
        "        print('=' * 30, 'Similar Text: {} || Similar Score: {}'.format(index+1, np.round(cosine_similarities_n[top_Indices[index]], 3)), '=' * 30, '\\n')\n",
        "        print(sim_text, '\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vo7TrscOulNr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "a4e90e26-6394-4cc8-ccae-4feebd1166ca"
      },
      "source": [
        "query_index = 16\n",
        "query_text = df_tweets.loc[test_indices[query_index], \"Text\"]\n",
        "query_text_vector = test_vectors[query_index].reshape(1, -1)\n",
        "print_similar_texts(query_text, query_text_vector, train_vectors, train_indices, df_tweets, n = 5)"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Input Text:\n",
            " coffee tastes so good at night🖤 \n",
            "\n",
            "============================== Similar Text: 1 || Similar Score: 0.9330000281333923 ============================== \n",
            "\n",
            "I’ve been making my own iced coffee most days and its sooo good 😋 \n",
            "\n",
            "============================== Similar Text: 2 || Similar Score: 0.9120000004768372 ============================== \n",
            "\n",
            "my cake came out so fire 😭😭🤤🤤 \n",
            "\n",
            "============================== Similar Text: 3 || Similar Score: 0.9100000262260437 ============================== \n",
            "\n",
            "I mean iced coffee sounds good too but the whipped cream from there 😋😋😋 \n",
            "\n",
            "============================== Similar Text: 4 || Similar Score: 0.9089999794960022 ============================== \n",
            "\n",
            "Coffee ain’t hittin no more 😫 \n",
            "\n",
            "============================== Similar Text: 5 || Similar Score: 0.9049999713897705 ============================== \n",
            "\n",
            "@Shithotish @Coffee_Ink_ Should be sat in my pair of acres😅 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dsr_-nqayRpp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def find_similar_n(train_matrix, train_indices, test_matrix, test_indices, test_set_df, df_tweets, n=5):\n",
        "    similar_texts_list = []\n",
        "    similar_scores_list = []\n",
        "    similar_top_score_list = []\n",
        "    similar_themes_list = []\n",
        "    similar_top_themes_list = []\n",
        "    for vector in test_matrix:\n",
        "        cosine_similarities_n = cosine_similarity(vector.reshape(1, -1), train_matrix).flatten()\n",
        "        similar_doc_indices =  cosine_similarities_n.argsort()[::-1][:n]\n",
        "        top_tweet_Indices = train_indices[similar_doc_indices]\n",
        "        \n",
        "        similar_texts = [text for text in df_tweets.loc[top_tweet_Indices, \"Text\"]]\n",
        "        similar_texts_list.append(similar_texts)\n",
        "        \n",
        "        similar_scores = [np.round(score, 3) for score in cosine_similarities_n[similar_doc_indices]]\n",
        "        similar_scores_list.append(similar_scores)\n",
        "        similar_top_score_list.append(similar_scores[0])\n",
        "                                                                   \n",
        "        similar_themes = [theme for theme in df_tweets.loc[top_tweet_Indices, \"Theme\"]]\n",
        "        similar_themes_list.append(similar_themes)\n",
        "        \n",
        "        top_similar_theme = max(set(similar_themes), key=lambda x: similar_themes.count(x))\n",
        "        similar_top_themes_list.append(top_similar_theme)\n",
        "    \n",
        "    df = test_set_df.copy() \n",
        "    df[\"original_theme\"] = df_tweets.loc[test_indices, \"Theme\"]\n",
        "    df[\"similar_texts\"] = similar_texts_list\n",
        "    df[\"similar_scores\"] = similar_scores_list  \n",
        "    df[\"top_similar_score\"] = similar_top_score_list\n",
        "    df[\"similar_themes\"] = similar_themes_list\n",
        "    df[\"top_similar_themes\"] = similar_top_themes_list\n",
        "    return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zL4-evV9y25k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "3e207dba-1f65-45c3-f011-bce09185c67b"
      },
      "source": [
        "similar_test_df = find_similar_n(train_vectors, train_indices, test_vectors, test_indices, test_set, df_tweets, n=5)\n",
        "similar_test_df.head()"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>original_theme</th>\n",
              "      <th>similar_texts</th>\n",
              "      <th>similar_scores</th>\n",
              "      <th>top_similar_score</th>\n",
              "      <th>similar_themes</th>\n",
              "      <th>top_similar_themes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6953</th>\n",
              "      <td>RT @Essence: Join us TOMORROW, 4/27 at 7 PM ES...</td>\n",
              "      <td>Bank/Financial</td>\n",
              "      <td>[RT @HaggertyColleen: Amazing conversation w @...</td>\n",
              "      <td>[0.955, 0.953, 0.952, 0.951, 0.944]</td>\n",
              "      <td>0.955</td>\n",
              "      <td>[Bank/Financial, Bank/Financial, Bank/Financia...</td>\n",
              "      <td>Bank/Financial</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6031</th>\n",
              "      <td>RT @Jordan_Sather_: I can (almost) guarantee y...</td>\n",
              "      <td>nasa</td>\n",
              "      <td>[RT @Jordan_Sather_: I can (almost) guarantee ...</td>\n",
              "      <td>[1.0, 1.0, 1.0, 1.0, 1.0]</td>\n",
              "      <td>1.000</td>\n",
              "      <td>[nasa, nasa, nasa, nasa, nasa]</td>\n",
              "      <td>nasa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>239</th>\n",
              "      <td>@roth_jroth1515 Hi Jennifer. Do you have a mom...</td>\n",
              "      <td>Bank/Financial</td>\n",
              "      <td>[@PRDR123 Just following up with you. Do you s...</td>\n",
              "      <td>[0.968, 0.967, 0.965, 0.965, 0.964]</td>\n",
              "      <td>0.968</td>\n",
              "      <td>[Bank/Financial, Bank/Financial, Bank/Financia...</td>\n",
              "      <td>Bank/Financial</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5720</th>\n",
              "      <td>RT @gguksluver: jimins face when he realized j...</td>\n",
              "      <td>cake</td>\n",
              "      <td>[RT @gguksluver: jimins face when he realized ...</td>\n",
              "      <td>[1.0, 1.0, 0.956, 0.952, 0.952]</td>\n",
              "      <td>1.000</td>\n",
              "      <td>[cake, cake, cake, cake, cake]</td>\n",
              "      <td>cake</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7102</th>\n",
              "      <td>RT @SaralPatel: Shri @RahulGandhi will be inte...</td>\n",
              "      <td>covid-19</td>\n",
              "      <td>[RT @INCIndia: Shri @RahulGandhi will be inter...</td>\n",
              "      <td>[0.996, 0.996, 0.988, 0.919, 0.917]</td>\n",
              "      <td>0.996</td>\n",
              "      <td>[covid-19, covid-19, covid-19, covid-19, covid...</td>\n",
              "      <td>covid-19</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   text  ... top_similar_themes\n",
              "6953  RT @Essence: Join us TOMORROW, 4/27 at 7 PM ES...  ...     Bank/Financial\n",
              "6031  RT @Jordan_Sather_: I can (almost) guarantee y...  ...               nasa\n",
              "239   @roth_jroth1515 Hi Jennifer. Do you have a mom...  ...     Bank/Financial\n",
              "5720  RT @gguksluver: jimins face when he realized j...  ...               cake\n",
              "7102  RT @SaralPatel: Shri @RahulGandhi will be inte...  ...           covid-19\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWmU8K1W1ugT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7d0522f8-a235-4e56-eb45-d402635c0dfc"
      },
      "source": [
        "accuracy = 100 * np.sum(similar_test_df[\"original_theme\"] == similar_test_df[\"top_similar_themes\"])/similar_test_df.shape[0]\n",
        "print(\"Accuracy on test data in predicting theme: {}%\".format(np.round(accuracy,2)))"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy on test data in predicting theme: 72.55%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZH77i9U9B2Sx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "similar_test_df.to_csv(\"BERT_similar_test_tweets.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0wHZcFrNGzNk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.listdir('.')\n",
        "! cp -r ./BERT_similar_test_tweets.csv './drive/My Drive/MIDS/docSimilarity/model_save/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z5NOOutBRskG",
        "colab_type": "text"
      },
      "source": [
        "# Nearest Euclidean:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKmMR-eJ1_3W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def print_nearest_euclidean_texts(query_text, query_text_vector,  train_matrix, train_indices, df_tweets, n = 5):\n",
        "    euclidean_distance = distance.cdist(sample_vector.reshape(1, -1), train_vectors, 'euclidean').flatten() \n",
        "    top_Indices = euclidean_distance.argsort()[:n]\n",
        "    top_tweet_Indices = train_indices[top_Indices]\n",
        "    \n",
        "    print('\\nInput Text:\\n {} \\n'.format(query_text))\n",
        "    for index, sim_text in enumerate(df_tweets.loc[top_tweet_Indices, \"Text\"]):\n",
        "        print('=' * 30, 'Similar Text: {} || Euclidean Distance: {}'.format(index+1, np.round(euclidean_distance[top_Indices[index]], 3)), '=' * 30, '\\n')\n",
        "        print(sim_text, '\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5VsCGqIQ2W7h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "e9959072-c7d7-41a8-cd95-3a5d2e4d7a70"
      },
      "source": [
        "query_index = 16\n",
        "query_text = df_tweets.loc[test_indices[query_index], \"Text\"]\n",
        "query_text_vector = test_vectors[query_index].reshape(1, -1)\n",
        "print_nearest_euclidean_texts(query_text, query_text_vector, train_vectors, train_indices, df_tweets, n = 5)"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Input Text:\n",
            " coffee tastes so good at night🖤 \n",
            "\n",
            "============================== Similar Text: 1 || Euclidean Distance: 3.701 ============================== \n",
            "\n",
            "@PRDR123 Just following up with you. Do you still need assistance? ^B \n",
            "\n",
            "============================== Similar Text: 2 || Euclidean Distance: 3.762 ============================== \n",
            "\n",
            "@PRDR123 Hi Peter. Thank you for the feedback. Is there something I can help you with? ^B \n",
            "\n",
            "============================== Similar Text: 3 || Euclidean Distance: 3.8 ============================== \n",
            "\n",
            "@PabloLlama88 Please try your call again at a later time. Thank you. ^B \n",
            "\n",
            "============================== Similar Text: 4 || Euclidean Distance: 3.886 ============================== \n",
            "\n",
            "@mcsean123 Hi there! Are you available to chat? ^Vee \n",
            "\n",
            "============================== Similar Text: 5 || Euclidean Distance: 3.89 ============================== \n",
            "\n",
            "@kgmerz Hi Karen. I would be happy to look into this. Do you have time to chat securely off Twitter so I can look at your account? ^B \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-h-guNn29Sz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def find_nearest_n(train_matrix, train_indices, test_matrix, test_indices, test_set_df, df_tweets, n=5):\n",
        "    similar_texts_list = []\n",
        "    euclidean_distances_list = []\n",
        "    euclidean_nearest_distance_list = []   \n",
        "    similar_themes_list = []\n",
        "    similar_top_themes_list = []\n",
        "    for vector in test_matrix:\n",
        "        euclidean_distance = distance.cdist(vector.reshape(1, -1), train_vectors, 'euclidean').flatten()\n",
        "        nearest_doc_indices =  euclidean_distance.argsort()[:n]        \n",
        "        top_tweet_Indices = train_indices[nearest_doc_indices]\n",
        "        \n",
        "        similar_texts = [text for text in df_tweets.loc[top_tweet_Indices, \"Text\"]]\n",
        "        similar_texts_list.append(similar_texts)\n",
        "        \n",
        "        euclidean_distances = [np.round(score, 3) for score in euclidean_distance[nearest_doc_indices]]\n",
        "        euclidean_distances_list.append(euclidean_distances)\n",
        "        euclidean_nearest_distance_list.append(euclidean_distances[0])\n",
        "                                                                   \n",
        "        similar_themes = [theme for theme in df_tweets.loc[top_tweet_Indices, \"Theme\"]]\n",
        "        similar_themes_list.append(similar_themes)\n",
        "        \n",
        "        top_similar_theme = max(set(similar_themes), key=lambda x: similar_themes.count(x))\n",
        "        similar_top_themes_list.append(top_similar_theme)\n",
        "    \n",
        "    df = test_set_df.copy() \n",
        "    df[\"original_theme\"] = df_tweets.loc[test_indices, \"Theme\"]\n",
        "    df[\"similar_texts\"] = similar_texts_list\n",
        "    df[\"euclidean_distances\"] = euclidean_distances_list  \n",
        "    df[\"nearest_euclidean_distance\"] = euclidean_nearest_distance_list\n",
        "    df[\"similar_themes\"] = similar_themes_list\n",
        "    df[\"top_similar_themes\"] = similar_top_themes_list\n",
        "    return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSgc4xkeRV5C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "40508e2e-277c-4836-a172-2466e747a974"
      },
      "source": [
        "nearest_test_df = find_nearest_n(train_vectors, train_indices, test_vectors, test_indices, test_set, df_tweets)\n",
        "nearest_test_df.head()"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>original_theme</th>\n",
              "      <th>similar_texts</th>\n",
              "      <th>euclidean_distances</th>\n",
              "      <th>nearest_euclidean_distance</th>\n",
              "      <th>similar_themes</th>\n",
              "      <th>top_similar_themes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6953</th>\n",
              "      <td>RT @Essence: Join us TOMORROW, 4/27 at 7 PM ES...</td>\n",
              "      <td>Bank/Financial</td>\n",
              "      <td>[RT @HaggertyColleen: Amazing conversation w @...</td>\n",
              "      <td>[4.126, 4.255, 4.258, 4.293, 4.663]</td>\n",
              "      <td>4.126</td>\n",
              "      <td>[Bank/Financial, Bank/Financial, Bank/Financia...</td>\n",
              "      <td>Bank/Financial</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6031</th>\n",
              "      <td>RT @Jordan_Sather_: I can (almost) guarantee y...</td>\n",
              "      <td>nasa</td>\n",
              "      <td>[RT @Jordan_Sather_: I can (almost) guarantee ...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
              "      <td>0.000</td>\n",
              "      <td>[nasa, nasa, nasa, nasa, nasa]</td>\n",
              "      <td>nasa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>239</th>\n",
              "      <td>@roth_jroth1515 Hi Jennifer. Do you have a mom...</td>\n",
              "      <td>Bank/Financial</td>\n",
              "      <td>[@PRDR123 Just following up with you. Do you s...</td>\n",
              "      <td>[3.701, 3.762, 3.8, 3.886, 3.89]</td>\n",
              "      <td>3.701</td>\n",
              "      <td>[Bank/Financial, Bank/Financial, Bank/Financia...</td>\n",
              "      <td>Bank/Financial</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5720</th>\n",
              "      <td>RT @gguksluver: jimins face when he realized j...</td>\n",
              "      <td>cake</td>\n",
              "      <td>[RT @gguksluver: jimins face when he realized ...</td>\n",
              "      <td>[0.0, 0.0, 4.094, 4.297, 4.297]</td>\n",
              "      <td>0.000</td>\n",
              "      <td>[cake, cake, cake, dog, dog]</td>\n",
              "      <td>cake</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7102</th>\n",
              "      <td>RT @SaralPatel: Shri @RahulGandhi will be inte...</td>\n",
              "      <td>covid-19</td>\n",
              "      <td>[RT @INCIndia: Shri @RahulGandhi will be inter...</td>\n",
              "      <td>[1.338, 1.338, 2.242, 5.838, 5.891]</td>\n",
              "      <td>1.338</td>\n",
              "      <td>[covid-19, covid-19, covid-19, covid-19, covid...</td>\n",
              "      <td>covid-19</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   text  ... top_similar_themes\n",
              "6953  RT @Essence: Join us TOMORROW, 4/27 at 7 PM ES...  ...     Bank/Financial\n",
              "6031  RT @Jordan_Sather_: I can (almost) guarantee y...  ...               nasa\n",
              "239   @roth_jroth1515 Hi Jennifer. Do you have a mom...  ...     Bank/Financial\n",
              "5720  RT @gguksluver: jimins face when he realized j...  ...               cake\n",
              "7102  RT @SaralPatel: Shri @RahulGandhi will be inte...  ...           covid-19\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I19THYGZRoi3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b20f6cea-8c5b-4e2a-86de-3b93879f30c9"
      },
      "source": [
        "accuracy = 100 * np.sum(nearest_test_df[\"original_theme\"] == nearest_test_df[\"top_similar_themes\"])/nearest_test_df.shape[0]\n",
        "print(\"Accuracy on test data in predicting theme: {}%\".format(np.round(accuracy,2)))"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy on test data in predicting theme: 72.68%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vc9m2POaR5mN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nearest_test_df.to_csv(\"BERT_nearest_test_tweets.csv\")\n",
        "! cp -r ./BERT_nearest_test_tweets.csv './drive/My Drive/MIDS/docSimilarity/model_save/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ywe4qEO8WVyh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}