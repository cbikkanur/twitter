{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "documentSimilarity_BERT_v2.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMKBuzjCSwBzYCgxa7T8H4w",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "84956b3df4c74080b7f92929b0106d4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_3751673b97b848e791204302eb8d00e5",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_031f8d4c404747379104b55e564ac262",
              "IPY_MODEL_67f1915c2f914d1b82b7489b9b5ce1f4"
            ]
          }
        },
        "3751673b97b848e791204302eb8d00e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "031f8d4c404747379104b55e564ac262": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ad770a177b2c482b9ca2655895c47a03",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2f344e5477d54bea91b6c13b205fc9ec"
          }
        },
        "67f1915c2f914d1b82b7489b9b5ce1f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a36e93c2c9524bfd810b2dff1a841b5b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 631kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_483491ca269f4bec83cdf1a86a153080"
          }
        },
        "ad770a177b2c482b9ca2655895c47a03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2f344e5477d54bea91b6c13b205fc9ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a36e93c2c9524bfd810b2dff1a841b5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "483491ca269f4bec83cdf1a86a153080": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "58c6322f08d64966a48f44a70e1ee1de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ec2356dd0c4c4498bb24dd03f71d9f5e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_250e18ceb5b14e8c9f9eb803832b4fa2",
              "IPY_MODEL_e11ad1c1fe324bc484edf5d284b86b43"
            ]
          }
        },
        "ec2356dd0c4c4498bb24dd03f71d9f5e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "250e18ceb5b14e8c9f9eb803832b4fa2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_7ee54d8d839d49fba13679719a5c256d",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_820e85f4dca946d7ad1336c3ec837fe9"
          }
        },
        "e11ad1c1fe324bc484edf5d284b86b43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1a41280d6b924218aa0926affffb36dc",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:15&lt;00:00, 27.4B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_69de6cb071b44ebe8329c181631189c2"
          }
        },
        "7ee54d8d839d49fba13679719a5c256d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "820e85f4dca946d7ad1336c3ec837fe9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1a41280d6b924218aa0926affffb36dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "69de6cb071b44ebe8329c181631189c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2c8e2053d9654b59bc8844197430c314": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f6b7afc97fde49768c4f873501bcf8d3",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f7ffcc235b014865ad58adf74871086e",
              "IPY_MODEL_36eaf2c3e4674a0f9069fe5fa615f8e9"
            ]
          }
        },
        "f6b7afc97fde49768c4f873501bcf8d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f7ffcc235b014865ad58adf74871086e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e0a09e50537d4c4c98470f1cd45cd379",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4cde3457b9164a45af5b04da039c5bbf"
          }
        },
        "36eaf2c3e4674a0f9069fe5fa615f8e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_76c12c04540949e38458870a8261ab1a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [00:15&lt;00:00, 29.4MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5aa1d01498d246069a74bae550c3bf91"
          }
        },
        "e0a09e50537d4c4c98470f1cd45cd379": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4cde3457b9164a45af5b04da039c5bbf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "76c12c04540949e38458870a8261ab1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5aa1d01498d246069a74bae550c3bf91": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cbikkanur/twitter/blob/master/documentSimilarity_BERT_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HN2uyOrhG9i8",
        "colab_type": "code",
        "outputId": "6369a7d0-89dc-475f-e7ec-c8e563e85e85",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import csv\n",
        "import os\n",
        "import time\n",
        "import datetime\n",
        "print(os.listdir(\".\"))\n",
        "from scipy.spatial import distance\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.pipeline import Pipeline\n",
        "np.random.seed(0)\n",
        "\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['.config', 'sample_data']\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5gRJ2QCg8eG",
        "colab_type": "code",
        "outputId": "69b5dc13-1637-4cd9-cb2e-ac16c709c8d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "# Go to Edit > Notebook Settings > Hardware accelerator > GPU\n",
        "device_name = tf.test.gpu_device_name()\n",
        "print(device_name)\n",
        "\n",
        "import torch\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device('cuda')\n",
        "  print('We will use {} {}GPU(s)'.format(torch.cuda.device_count(), torch.cuda.get_device_name() ))\n",
        "else:\n",
        "  device = torch.device('cuda')\n",
        "  print('No GPU(s) available; we will use \"cpu\"')\n",
        "\n",
        "device=torch.device('cuda')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/device:GPU:0\n",
            "We will use 1 Tesla T4GPU(s)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Nau6J3cII9B",
        "colab_type": "code",
        "outputId": "c7821911-00cb-4471-cce0-5a904d764735",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "# Run this cell to mount your Google Drive.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3L9M0ACxIwYX",
        "colab_type": "code",
        "outputId": "8b8cd5ff-9566-4270-8854-9a9668353c0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "DRIVE_PATH = \"/content/drive/My Drive/MIDS/docSimilarity/\"\n",
        "\n",
        "print(os.listdir(DRIVE_PATH))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['CosineSimilarity.ipynb', 'getTwitterData_TweePy.ipynb', 'cbikkanur_twitter_credentials.json', 'cbikkanur_twitter_credentials.ipynb', 'tweets_04232020.csv', 'SearchTweets.csv', 'BankTweets.csv', 'documentSimilarity.ipynb', 'tweets_04242020.csv', 'SearchTweets_04242020.csv', 'BankTweets_04242020.csv', 'SearchTweets_04252020.csv', 'tweets_04252020.csv', 'BankTweets_04252020.csv', 'documentSimilarity_TfIdf.ipynb.txt', 'SearchTweets_04262020.csv', 'BankTweets_04262020.csv', 'tweets_04262020.csv', '.ipynb_checkpoints', 'model_save', 'train_vectors.npy', 'test_vectors.npy', 'getTwitterData.ipynb', 'SearchTweets_04292020.csv', 'BankTweets_04292020.csv', 'tweets_04292020.csv', 'BankTweets_04302020.csv', 'tweets_04302020.csv', 'SearchTweets_04302020.csv', 'TfIdf_similar_test_tweets.csv', 'documentSimilarity_TfIdf.ipynb']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yF_J22-1I-RR",
        "colab_type": "code",
        "outputId": "372eaed4-e90b-436e-b8b4-16054a2940e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "all_files = [DRIVE_PATH+'tweets_04232020.csv', DRIVE_PATH+'./tweets_04242020.csv', DRIVE_PATH+'./tweets_04252020.csv',\n",
        "             DRIVE_PATH+'./tweets_04262020.csv', DRIVE_PATH+'./tweets_04292020.csv', DRIVE_PATH+'./tweets_04302020.csv']\n",
        "\n",
        "df_list = []\n",
        "for filename in all_files:\n",
        "    df_list.append(pd.read_csv(filename, sep=',',header=0, encoding='utf-8', index_col = 0))\n",
        "    \n",
        "df_tweets = pd.concat(df_list, ignore_index=True)\n",
        "df_tweets.head()   "
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tweet_Id</th>\n",
              "      <th>User_Id</th>\n",
              "      <th>User_Name</th>\n",
              "      <th>User_Screen_Name</th>\n",
              "      <th>Theme</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1253375593271394312</td>\n",
              "      <td>80374332</td>\n",
              "      <td>Citibank</td>\n",
              "      <td>Citibank</td>\n",
              "      <td>Bank/Financial</td>\n",
              "      <td>Registering for online access and activating y...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1253322747851296768</td>\n",
              "      <td>80374332</td>\n",
              "      <td>Citibank</td>\n",
              "      <td>Citibank</td>\n",
              "      <td>Bank/Financial</td>\n",
              "      <td>Protect your CARES Act payments: Validate comm...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1253066045700681731</td>\n",
              "      <td>80374332</td>\n",
              "      <td>Citibank</td>\n",
              "      <td>Citibank</td>\n",
              "      <td>Bank/Financial</td>\n",
              "      <td>It’s simple to set up a payment account in the...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1252960358454767616</td>\n",
              "      <td>80374332</td>\n",
              "      <td>Citibank</td>\n",
              "      <td>Citibank</td>\n",
              "      <td>Bank/Financial</td>\n",
              "      <td>We’re committed to helping provide the support...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1252673469852143618</td>\n",
              "      <td>80374332</td>\n",
              "      <td>Citibank</td>\n",
              "      <td>Citibank</td>\n",
              "      <td>Bank/Financial</td>\n",
              "      <td>Protect Yourself from COVID-19 Scams: Don’t re...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              Tweet_Id  ...                                               Text\n",
              "0  1253375593271394312  ...  Registering for online access and activating y...\n",
              "1  1253322747851296768  ...  Protect your CARES Act payments: Validate comm...\n",
              "2  1253066045700681731  ...  It’s simple to set up a payment account in the...\n",
              "3  1252960358454767616  ...  We’re committed to helping provide the support...\n",
              "4  1252673469852143618  ...  Protect Yourself from COVID-19 Scams: Don’t re...\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RR3S0KmLJvyA",
        "colab_type": "code",
        "outputId": "0dc5672a-5dba-4f14-8997-482c928fc313",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "df_tweets.drop_duplicates([\"Text\"], inplace=True) # remove duplicates in place and reset index\n",
        "df_tweets = df_tweets.reset_index(drop=True)\n",
        "df_tweets.shape"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7700, 6)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sy_j2XQDUrO_",
        "colab_type": "text"
      },
      "source": [
        "## Preprocessing:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YodXojYDJ2O8",
        "colab_type": "code",
        "outputId": "b8386a46-cee0-439e-e11b-f5fe6ea7d7ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "query_index = 10\n",
        "df = pd.DataFrame()\n",
        "df['text'] = df_tweets['Text']\n",
        "print('{:=^100}\\n\\n {}'.format(' Raw text ', df.text.loc[query_index])) \n",
        "\n",
        "df['text'] = df['text'].str.replace('http\\S+', '') # removing URLs\n",
        "df['text'] = df['text'].str.replace('[^A-Za-z0-9]+', ' ') # retain only alphanumeric\n",
        "df['text'] = df['text'].map(lambda x: WordNetLemmatizer().lemmatize(x)) # lemmatization\n",
        "df['text'] = df['text'].map(lambda x: x.lower()) # to lower case\n",
        "\n",
        "print('\\n{:=^100}\\n\\n {}'.format(' Preprocessed text ', df.text.loc[query_index])) "
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "============================================= Raw text =============================================\n",
            "\n",
            " To our heroes going out into the world each day – thank you. Citi is supporting COVID-19 relief efforts around the world to help those bravely showing up for the rest of us. https://t.co/oaknGpLLlX https://t.co/wRZ7o6lupM\n",
            "\n",
            "======================================== Preprocessed text =========================================\n",
            "\n",
            " to our heroes going out into the world each day thank you citi is supporting covid 19 relief efforts around the world to help those bravely showing up for the rest of us \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S0q6wqLlJ5CS",
        "colab_type": "code",
        "outputId": "95db1b2f-6ade-4c30-af60-bf8b3d75adbf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "total_indices_size = df.shape[0]\n",
        "train_size = 0.8\n",
        "train_indices_size = int(train_size * total_indices_size)\n",
        "test_indices_size = total_indices_size - train_indices_size\n",
        "print('total records: {}\\n trainig_set record: {}\\n test_set records: {}'.format(total_indices_size, train_indices_size, test_indices_size))\n",
        "\n",
        "total_indices_array = np.array([x for x in range(total_indices_size)])\n",
        "np.random.shuffle(total_indices_array)\n",
        "train_indices, test_indices = total_indices_array[:train_indices_size], total_indices_array[train_indices_size:]"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total records: 7700\n",
            " trainig_set record: 6160\n",
            " test_set records: 1540\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HelsofoBJ9uD",
        "colab_type": "code",
        "outputId": "9bf4b264-3b55-4db4-c4f0-daa4fd87a7c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "train_set, test_set = df.loc[train_indices], df.loc[test_indices]\n",
        "train_set[:5]"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2241</th>\n",
              "      <td>penelopeonthego lindseyboylan heerjeet perfec...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4644</th>\n",
              "      <td>hey fedex have you seen my fancy coffee machine</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6446</th>\n",
              "      <td>promote to team 4 akb48 at 23 march 2012 and m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7406</th>\n",
              "      <td>rt cbcolympics this canadian athlete will be h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>912</th>\n",
              "      <td>kllingboys the feeling is mutual talk about a...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   text\n",
              "2241   penelopeonthego lindseyboylan heerjeet perfec...\n",
              "4644   hey fedex have you seen my fancy coffee machine \n",
              "6446  promote to team 4 akb48 at 23 march 2012 and m...\n",
              "7406  rt cbcolympics this canadian athlete will be h...\n",
              "912    kllingboys the feeling is mutual talk about a..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-zYjqYE5KdZn",
        "colab_type": "code",
        "outputId": "61366fcf-2674-4d19-abfd-e37532263fff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        }
      },
      "source": [
        "# Documentation for transformers: https://huggingface.co/transformers/index.html\n",
        "! pip install transformers"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/78/92cedda05552398352ed9784908b834ee32a0bd071a9b32de287327370b7/transformers-2.8.0-py3-none-any.whl (563kB)\n",
            "\u001b[K     |████████████████████████████████| 573kB 9.4MB/s \n",
            "\u001b[?25hCollecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/98/2c/8df20f3ac6c22ac224fff307ebc102818206c53fc454ecd37d8ac2060df5/sentencepiece-0.1.86-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 61.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/99/50/93509f906a40bffd7d175f97fd75ea328ad9bd91f48f59c4bd084c94a25e/sacremoses-0.0.41.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 62.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.12.47)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.38.0)\n",
            "Collecting tokenizers==0.5.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/3f/73c881ea4723e43c1e9acf317cf407fab3a278daab3a69c98dcac511c04f/tokenizers-0.5.2-cp36-cp36m-manylinux1_x86_64.whl (3.7MB)\n",
            "\u001b[K     |████████████████████████████████| 3.7MB 44.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.4.5.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
            "Requirement already satisfied: botocore<1.16.0,>=1.15.47 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.15.47)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.5)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.47->boto3->transformers) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.47->boto3->transformers) (2.8.1)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.41-cp36-none-any.whl size=893334 sha256=e990661ffc974f3136145f0007b718b97e10c444f87ca9f4a5c153c9d8e13f6a\n",
            "  Stored in directory: /root/.cache/pip/wheels/22/5a/d4/b020a81249de7dc63758a34222feaa668dbe8ebfe9170cc9b1\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sentencepiece, sacremoses, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.41 sentencepiece-0.1.86 tokenizers-0.5.2 transformers-2.8.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3asqvTaZK1Lt",
        "colab_type": "code",
        "outputId": "48ff9280-c779-4197-a6e0-d558b055c2e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "84956b3df4c74080b7f92929b0106d4f",
            "3751673b97b848e791204302eb8d00e5",
            "031f8d4c404747379104b55e564ac262",
            "67f1915c2f914d1b82b7489b9b5ce1f4",
            "ad770a177b2c482b9ca2655895c47a03",
            "2f344e5477d54bea91b6c13b205fc9ec",
            "a36e93c2c9524bfd810b2dff1a841b5b",
            "483491ca269f4bec83cdf1a86a153080",
            "58c6322f08d64966a48f44a70e1ee1de",
            "ec2356dd0c4c4498bb24dd03f71d9f5e",
            "250e18ceb5b14e8c9f9eb803832b4fa2",
            "e11ad1c1fe324bc484edf5d284b86b43",
            "7ee54d8d839d49fba13679719a5c256d",
            "820e85f4dca946d7ad1336c3ec837fe9",
            "1a41280d6b924218aa0926affffb36dc",
            "69de6cb071b44ebe8329c181631189c2",
            "2c8e2053d9654b59bc8844197430c314",
            "f6b7afc97fde49768c4f873501bcf8d3",
            "f7ffcc235b014865ad58adf74871086e",
            "36eaf2c3e4674a0f9069fe5fa615f8e9",
            "e0a09e50537d4c4c98470f1cd45cd379",
            "4cde3457b9164a45af5b04da039c5bbf",
            "76c12c04540949e38458870a8261ab1a",
            "5aa1d01498d246069a74bae550c3bf91"
          ]
        }
      },
      "source": [
        "import torch\n",
        "from transformers import BertTokenizer, BertModel, BertForSequenceClassification\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', output_hidden_states = True ) # return hidden layers\n",
        "model.cuda"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "84956b3df4c74080b7f92929b0106d4f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=231508, style=ProgressStyle(description_wid…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "58c6322f08d64966a48f44a70e1ee1de",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=433, style=ProgressStyle(description_width=…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2c8e2053d9654b59bc8844197430c314",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=440473133, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method Module.cuda of BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ydr44zz0WVOp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def vectorize_sentence(tokenizer, model, text):\n",
        "  MAX_LENGTH = 100\n",
        "  input_ids = tokenizer.encode(text, add_special_tokens=True, max_length=MAX_LENGTH) # encode for tokenizing\n",
        "  padded_sequences = pad_sequences([input_ids], maxlen=MAX_LENGTH, dtype='long', truncating='post', padding='post') # pad 0 at the end of sentence until MAX_LENGTH\n",
        "  input_ids = padded_sequences[0] # remove the outer list\n",
        "  attention_mask = [int(i>0) for i in input_ids]\n",
        "\n",
        "  input_ids = torch.tensor(input_ids)\n",
        "  attention_mask = torch.tensor(attention_mask)\n",
        "\n",
        "  input_ids = input_ids.unsqueeze(0) # Extra dimension for batch\n",
        "  attention_mask = attention_mask.unsqueeze(0)  # Extra dimension for batch\n",
        "\n",
        "  model.eval() # Only forward pass\n",
        "  input_ids.to(device) # https://github.com/huggingface/transformers/blob/master/notebooks/02-transformers.ipynb\n",
        "  attention_mask.to(device)\n",
        "\n",
        "  with torch.no_grad(): # No gradient descent n\n",
        "    logits, encoded_layers = model(input_ids = input_ids, token_type_ids = None, attention_mask = attention_mask)\n",
        "    last_layer = 12\n",
        "    batch = 0\n",
        "    last_token_index = 0 \n",
        "\n",
        "    vector = encoded_layers[last_layer][batch][last_token_index]\n",
        "    vector = vector.detach().cpu().numpy()\n",
        "\n",
        "    return vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gGOR63eKLzwz",
        "colab_type": "code",
        "outputId": "65e1ef28-a68d-402e-8cd9-c4c778de349e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "sample_text = test_set.iloc[1].text\n",
        "sample_tokens = tokenizer.tokenize(sample_text)\n",
        "print('sample text: \\n{} \\n\\n BERT tokens for sample text: \\n{}'.format(sample_text, sample_tokens))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample text: \n",
            " candicontreras7 hello thank you for tweeting us so that we can better assist which u s issued amex card product do you have please do not release any personal identifiable information jad \n",
            "\n",
            " BERT tokens for sample text: \n",
            "['candi', '##con', '##tre', '##ras', '##7', 'hello', 'thank', 'you', 'for', 't', '##wee', '##ting', 'us', 'so', 'that', 'we', 'can', 'better', 'assist', 'which', 'u', 's', 'issued', 'am', '##ex', 'card', 'product', 'do', 'you', 'have', 'please', 'do', 'not', 'release', 'any', 'personal', 'identifiable', 'information', 'ja', '##d']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VPyFYQPHbYwd",
        "colab_type": "code",
        "outputId": "f5d53be4-62b0-4293-c143-951bff9f4161",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "sample_vector = vectorize_sentence(tokenizer, model, sample_text)\n",
        "print('Shape of the vector: {}'.format(sample_vector.shape))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of the vector: (768,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ua0wTgbUuDLp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def format_time(elapsed):\n",
        "  return str(datetime.timedelta(seconds = int(round(elapsed))))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SgpEpShXb2rH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def vectorize_dataset(df):\n",
        "  start_time = time.time()\n",
        "  embeddings = []\n",
        "  num_records = df.shape[0]\n",
        "  row_num = 0\n",
        "  for index, row in df.iterrows():\n",
        "    text = row['text']\n",
        "    if row_num % 200 == 0 and not row_num == 0:\n",
        "      elapsed = format_time(time.time() - start_time)\n",
        "      rows_per_sec = (time.time() - start_time) / row_num\n",
        "      remaining_sec = rows_per_sec * (num_records - row_num)\n",
        "      remaining = format_time(remaining_sec)\n",
        "      print(' comment {:>7,} of {:>7,}.    Elapsed: {:}. Remaining: {:}'.format(row_num, num_records, elapsed, remaining))\n",
        "    embeddings.append(vectorize_sentence(tokenizer, model, text))\n",
        "    row_num += 1\n",
        "  return  embeddings "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHdmBeGbk91K",
        "colab_type": "code",
        "outputId": "2eb24dad-e4fc-4925-9ba7-88c24d082562",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        }
      },
      "source": [
        "train_set_embeddings = vectorize_dataset(train_set)\n",
        "train_vectors = np.stack(train_set_embeddings)\n",
        "train_vectors.shape"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " comment     200 of   6,160.    Elapsed: 0:00:41. Remaining: 0:20:07\n",
            " comment     400 of   6,160.    Elapsed: 0:01:21. Remaining: 0:19:26\n",
            " comment     600 of   6,160.    Elapsed: 0:02:01. Remaining: 0:18:44\n",
            " comment     800 of   6,160.    Elapsed: 0:02:41. Remaining: 0:18:01\n",
            " comment   1,000 of   6,160.    Elapsed: 0:03:21. Remaining: 0:17:19\n",
            " comment   1,200 of   6,160.    Elapsed: 0:04:01. Remaining: 0:16:37\n",
            " comment   1,400 of   6,160.    Elapsed: 0:04:41. Remaining: 0:15:54\n",
            " comment   1,600 of   6,160.    Elapsed: 0:05:20. Remaining: 0:15:13\n",
            " comment   1,800 of   6,160.    Elapsed: 0:05:59. Remaining: 0:14:31\n",
            " comment   2,000 of   6,160.    Elapsed: 0:06:39. Remaining: 0:13:50\n",
            " comment   2,200 of   6,160.    Elapsed: 0:07:18. Remaining: 0:13:09\n",
            " comment   2,400 of   6,160.    Elapsed: 0:07:58. Remaining: 0:12:28\n",
            " comment   2,600 of   6,160.    Elapsed: 0:08:38. Remaining: 0:11:49\n",
            " comment   2,800 of   6,160.    Elapsed: 0:09:16. Remaining: 0:11:07\n",
            " comment   3,000 of   6,160.    Elapsed: 0:09:55. Remaining: 0:10:27\n",
            " comment   3,200 of   6,160.    Elapsed: 0:10:34. Remaining: 0:09:46\n",
            " comment   3,400 of   6,160.    Elapsed: 0:11:13. Remaining: 0:09:06\n",
            " comment   3,600 of   6,160.    Elapsed: 0:11:51. Remaining: 0:08:26\n",
            " comment   3,800 of   6,160.    Elapsed: 0:12:30. Remaining: 0:07:46\n",
            " comment   4,000 of   6,160.    Elapsed: 0:13:09. Remaining: 0:07:06\n",
            " comment   4,200 of   6,160.    Elapsed: 0:13:48. Remaining: 0:06:26\n",
            " comment   4,400 of   6,160.    Elapsed: 0:14:26. Remaining: 0:05:47\n",
            " comment   4,600 of   6,160.    Elapsed: 0:15:05. Remaining: 0:05:07\n",
            " comment   4,800 of   6,160.    Elapsed: 0:15:43. Remaining: 0:04:27\n",
            " comment   5,000 of   6,160.    Elapsed: 0:16:22. Remaining: 0:03:48\n",
            " comment   5,200 of   6,160.    Elapsed: 0:17:00. Remaining: 0:03:08\n",
            " comment   5,400 of   6,160.    Elapsed: 0:17:39. Remaining: 0:02:29\n",
            " comment   5,600 of   6,160.    Elapsed: 0:18:17. Remaining: 0:01:50\n",
            " comment   5,800 of   6,160.    Elapsed: 0:18:56. Remaining: 0:01:11\n",
            " comment   6,000 of   6,160.    Elapsed: 0:19:34. Remaining: 0:00:31\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6160, 768)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vT5M5WZbko7F",
        "colab_type": "code",
        "outputId": "4a510916-d5a7-41cb-d98c-b91a634e45f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "test_set_embeddings = vectorize_dataset(test_set)\n",
        "test_vectors = np.stack(test_set_embeddings)\n",
        "test_vectors.shape\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " comment     200 of   1,540.    Elapsed: 0:00:38. Remaining: 0:04:14\n",
            " comment     400 of   1,540.    Elapsed: 0:01:16. Remaining: 0:03:37\n",
            " comment     600 of   1,540.    Elapsed: 0:01:54. Remaining: 0:02:59\n",
            " comment     800 of   1,540.    Elapsed: 0:02:32. Remaining: 0:02:21\n",
            " comment   1,000 of   1,540.    Elapsed: 0:03:10. Remaining: 0:01:43\n",
            " comment   1,200 of   1,540.    Elapsed: 0:03:48. Remaining: 0:01:05\n",
            " comment   1,400 of   1,540.    Elapsed: 0:04:26. Remaining: 0:00:27\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1540, 768)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pkpQ5CKllMoJ",
        "colab_type": "code",
        "outputId": "d0751f39-cef6-4727-b134-acd81797406e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "output_dir = './drive/My Drive/MIDS/docSimilarity/model_save/'\n",
        "print(os.listdir(\".\"))\n",
        "if not os.path.exists(output_dir):\n",
        "  print('directory does not exist')\n",
        "  os.makedirs(output_dir)\n",
        "\n",
        "np.save('train_vectors_alnum.npy', train_vectors)  \n",
        "np.save('test_vectors_alnum.npy', test_vectors)  \n",
        "\n",
        "! cp -r ./train_vectors_alnum.npy './drive/My Drive/MIDS/docSimilarity/model_save/'\n",
        "! cp -r ./test_vectors_alnum.npy './drive/My Drive/MIDS/docSimilarity/model_save/'"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['.config', 'drive', 'sample_data']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tgA1G9HqV3ok",
        "colab_type": "text"
      },
      "source": [
        "# Cosine Similarity:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ttF6eVxJugqj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def print_similar_texts(query_text, query_text_vector,  train_matrix, train_indices, df_tweets, n = 5):\n",
        "    cosine_similarities_n = cosine_similarity(query_text_vector, train_matrix).flatten()\n",
        "    top_Indices = cosine_similarities_n.argsort()[::-1][:n]\n",
        "    top_tweet_Indices = train_indices[top_Indices]\n",
        "    \n",
        "    print('\\nInput Text:\\n {} \\n'.format(query_text))\n",
        "    for index, sim_text in enumerate(df_tweets.loc[top_tweet_Indices, \"Text\"]):\n",
        "        print('=' * 30, 'Similar Text: {} || Similar Score: {}'.format(index+1, np.round(cosine_similarities_n[top_Indices[index]], 3)), '=' * 30, '\\n')\n",
        "        print(sim_text, '\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vo7TrscOulNr",
        "colab_type": "code",
        "outputId": "ef58a577-c7c1-4749-a1f6-0211320e36c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "source": [
        "query_index = 77\n",
        "query_text = df_tweets.loc[test_indices[query_index], \"Text\"]\n",
        "query_text_vector = test_vectors[query_index].reshape(1, -1)\n",
        "print_similar_texts(query_text, query_text_vector, train_vectors, train_indices, df_tweets, n = 5)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Input Text:\n",
            " @SasiUgarteTeves We haven't heard back from you. Please let us know if you need further assistance. ^Shaun https://t.co/gvC4jAOA9c \n",
            "\n",
            "============================== Similar Text: 1 || Similar Score: 0.9769999980926514 ============================== \n",
            "\n",
            "@amj663 We haven't heard back from you. Please let us know if you require further assistance. ^Shaun https://t.co/gvC4jAOA9c \n",
            "\n",
            "============================== Similar Text: 2 || Similar Score: 0.9739999771118164 ============================== \n",
            "\n",
            "@Anubhav28284 We haven't heard back from you. Please let us know if you require further assistance. ^Shaun https://t.co/gvC4jAOA9c \n",
            "\n",
            "============================== Similar Text: 3 || Similar Score: 0.972000002861023 ============================== \n",
            "\n",
            "@dbfact We haven't heard back from you. Please send a DM if further help is required. ^Shaun https://t.co/gvC4jAOA9c \n",
            "\n",
            "============================== Similar Text: 4 || Similar Score: 0.9710000157356262 ============================== \n",
            "\n",
            "@ag3982 We haven't heard back from you. Please send a DM if you need assistance. ^Shaun https://t.co/gvC4jAOA9c \n",
            "\n",
            "============================== Similar Text: 5 || Similar Score: 0.9710000157356262 ============================== \n",
            "\n",
            "@ImJenniferGrace Thanks for reaching out, if any other help is needed please let us know. ^Moe \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dsr_-nqayRpp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def find_similar_n(train_matrix, train_indices, test_matrix, test_indices, test_set_df, df_tweets, n=5):\n",
        "    similar_texts_list = []\n",
        "    similar_scores_list = []\n",
        "    similar_top_score_list = []\n",
        "    similar_themes_list = []\n",
        "    similar_top_themes_list = []\n",
        "    for vector in test_matrix:\n",
        "        cosine_similarities_n = cosine_similarity(vector.reshape(1, -1), train_matrix).flatten()\n",
        "        similar_doc_indices =  cosine_similarities_n.argsort()[::-1][:n]\n",
        "        top_tweet_Indices = train_indices[similar_doc_indices]\n",
        "        \n",
        "        similar_texts = [text for text in df_tweets.loc[top_tweet_Indices, \"Text\"]]\n",
        "        similar_texts_list.append(similar_texts)\n",
        "        \n",
        "        similar_scores = [np.round(score, 3) for score in cosine_similarities_n[similar_doc_indices]]\n",
        "        similar_scores_list.append(similar_scores)\n",
        "        similar_top_score_list.append(similar_scores[0])\n",
        "                                                                   \n",
        "        similar_themes = [theme for theme in df_tweets.loc[top_tweet_Indices, \"Theme\"]]\n",
        "        similar_themes_list.append(similar_themes)\n",
        "        \n",
        "        top_similar_theme = max(set(similar_themes), key=lambda x: similar_themes.count(x))\n",
        "        similar_top_themes_list.append(top_similar_theme)\n",
        "    \n",
        "    df = test_set_df.copy() \n",
        "    df[\"original_theme\"] = df_tweets.loc[test_indices, \"Theme\"]\n",
        "    df[\"similar_texts\"] = similar_texts_list\n",
        "    df[\"similar_scores\"] = similar_scores_list  \n",
        "    df[\"top_similar_score\"] = similar_top_score_list\n",
        "    df[\"similar_themes\"] = similar_themes_list\n",
        "    df[\"top_similar_themes\"] = similar_top_themes_list\n",
        "    return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zL4-evV9y25k",
        "colab_type": "code",
        "outputId": "5c17e949-edc8-4ad9-c08a-e86da86af6f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "similar_test_df = find_similar_n(train_vectors, train_indices, test_vectors, test_indices, test_set, df_tweets, n=10)\n",
        "similar_test_df.head()"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>original_theme</th>\n",
              "      <th>similar_texts</th>\n",
              "      <th>similar_scores</th>\n",
              "      <th>top_similar_score</th>\n",
              "      <th>similar_themes</th>\n",
              "      <th>top_similar_themes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4648</th>\n",
              "      <td>catnip coffee you dont have to give me a new ...</td>\n",
              "      <td>coffee</td>\n",
              "      <td>[RT @claylongs: Jerking off in the car up on m...</td>\n",
              "      <td>[0.935, 0.932, 0.929, 0.929, 0.928, 0.927, 0.9...</td>\n",
              "      <td>0.935</td>\n",
              "      <td>[car, cake, cake, cake, cake, cake, Bank/Finan...</td>\n",
              "      <td>cake</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>362</th>\n",
              "      <td>candicontreras7 hello thank you for tweeting ...</td>\n",
              "      <td>Bank/Financial</td>\n",
              "      <td>[@JTrey3 Hello, thank you for tweeting us. So ...</td>\n",
              "      <td>[0.996, 0.995, 0.995, 0.994, 0.992, 0.992, 0.9...</td>\n",
              "      <td>0.996</td>\n",
              "      <td>[Bank/Financial, Bank/Financial, Bank/Financia...</td>\n",
              "      <td>Bank/Financial</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4645</th>\n",
              "      <td>teekhi mirchh harriisqureshi lemme healuh maj...</td>\n",
              "      <td>coffee</td>\n",
              "      <td>[RT @guu_tara: doodle  ZERO(ver.metless) https...</td>\n",
              "      <td>[0.93, 0.922, 0.922, 0.919, 0.918, 0.918, 0.91...</td>\n",
              "      <td>0.930</td>\n",
              "      <td>[car, tokyo, ramadan, dog, coffee, nasa, cake,...</td>\n",
              "      <td>car</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2086</th>\n",
              "      <td>rt trumpwarroom are you kidding me michigan de...</td>\n",
              "      <td>covid-19</td>\n",
              "      <td>[RT @JCAPoquoson: Punished for telling the tru...</td>\n",
              "      <td>[0.919, 0.915, 0.911, 0.909, 0.908, 0.906, 0.9...</td>\n",
              "      <td>0.919</td>\n",
              "      <td>[covid-19, covid-19, nasa, dog, dog, covid-19,...</td>\n",
              "      <td>covid-19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2988</th>\n",
              "      <td>state rep whitsett nearly died from coronaviru...</td>\n",
              "      <td>covid-19</td>\n",
              "      <td>[RT @GOPChairwoman: State Rep. Whitsett nearly...</td>\n",
              "      <td>[0.903, 0.891, 0.89, 0.89, 0.889, 0.888, 0.888...</td>\n",
              "      <td>0.903</td>\n",
              "      <td>[covid-19, dog, covid-19, @Citi, covid-19, cov...</td>\n",
              "      <td>covid-19</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   text  ... top_similar_themes\n",
              "4648   catnip coffee you dont have to give me a new ...  ...               cake\n",
              "362    candicontreras7 hello thank you for tweeting ...  ...     Bank/Financial\n",
              "4645   teekhi mirchh harriisqureshi lemme healuh maj...  ...                car\n",
              "2086  rt trumpwarroom are you kidding me michigan de...  ...           covid-19\n",
              "2988  state rep whitsett nearly died from coronaviru...  ...           covid-19\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWmU8K1W1ugT",
        "colab_type": "code",
        "outputId": "a2c5e00d-b048-4c71-cb45-788e6cd5162d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "accuracy = 100 * np.sum(similar_test_df[\"original_theme\"] == similar_test_df[\"top_similar_themes\"])/similar_test_df.shape[0]\n",
        "print(\"Accuracy on test data in predicting theme: {}%\".format(np.round(accuracy,2)))"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy on test data in predicting theme: 72.4%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZH77i9U9B2Sx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "similar_test_df.to_csv(\"BERT_similar_test_tweets.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0wHZcFrNGzNk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.listdir('.')\n",
        "! cp -r ./BERT_similar_test_tweets.csv './drive/My Drive/MIDS/docSimilarity/model_save/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z5NOOutBRskG",
        "colab_type": "text"
      },
      "source": [
        "# Nearest Euclidean:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKmMR-eJ1_3W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def print_nearest_euclidean_texts(query_text, query_text_vector,  train_matrix, train_indices, df_tweets, n = 5):\n",
        "    euclidean_distance = distance.cdist(query_text_vector.reshape(1, -1), train_vectors, 'euclidean').flatten() \n",
        "    top_Indices = euclidean_distance.argsort()[:n]\n",
        "    top_tweet_Indices = train_indices[top_Indices]\n",
        "    \n",
        "    print('\\nInput Text:\\n {} \\n'.format(query_text))\n",
        "    for index, sim_text in enumerate(df_tweets.loc[top_tweet_Indices, \"Text\"]):\n",
        "        print('=' * 30, 'Similar Text: {} || Euclidean Distance: {}'.format(index+1, np.round(euclidean_distance[top_Indices[index]], 3)), '=' * 30, '\\n')\n",
        "        print(sim_text, '\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5VsCGqIQ2W7h",
        "colab_type": "code",
        "outputId": "8352e827-086f-453d-c79f-0a7904b7c654",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 632
        }
      },
      "source": [
        "query_index = 16\n",
        "query_text = df_tweets.loc[test_indices[query_index], \"Text\"]\n",
        "query_text_vector = test_vectors[query_index]\n",
        "print_nearest_euclidean_texts(query_text, query_text_vector, train_vectors, train_indices, df_tweets, n = 5)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Input Text:\n",
            " @DLoesch Correct. Trump said inject a disinfectant directly into a person, not lungs 🤣. Videos don't lie so pretty sad Dana is full #Trump lapdog today trying to deflect  #CorruptGOP #Cult45 #Covid_19 #TrumpIsAnIdiot \n",
            "\n",
            "https://t.co/nwx7n0VHv8 \n",
            "\n",
            "============================== Similar Text: 1 || Euclidean Distance: 4.391 ============================== \n",
            "\n",
            "RT @13chwar: this lucky dog\n",
            "\n",
            "#WeLoveJennie\n",
            "#HeartsForJennie \n",
            "@ygofficialblink https://t.co/hXmIr2czi1 \n",
            "\n",
            "============================== Similar Text: 2 || Euclidean Distance: 4.512 ============================== \n",
            "\n",
            "@Facetiouslyfun @IttyTater @PumpkinPatch200 @Ilovecanada13 @facepalmchris @MeowMixFan1 @TDenham1106 @chriscoastguy @a_sirup @Kimberly5179 @imnotgonnashare @Cmags1963 @justloo48273802 @StillMeowing @GrumpyLittle1 @Cdnwatcher @criticalandcon @Prissi_coffee @dia2031 @MrsLauraBski @Indieanabones @JediBlonde @sikhofyou1 @JJCrosstrainers @Radtastiical @onionisfinished @lacey19911 @Aquaryan1972 @mirandamohajrn @bericm @Jodie33392934 @no0n3 @SereneSerpent28 @christophelston @vb02md @CrustedNerd @maruzeh @AGillespie66 @nakitsura @sketchartist001 @BotheredWasp @morninglory75 @stevenm73890092 @Kasandroid @Avery85782409 @SBaumEvansmom @D_M_L_R @Loki69787441 @MenacingCrow I’ve been watching my sons activity and pray I’m not missing anything. I can joke about Yaniv but I care and will always be concerned about my child. We have seen the manipulative tactics employed by the likes of these degenerates and I want to do the best \n",
            "\n",
            "============================== Similar Text: 3 || Euclidean Distance: 4.519 ============================== \n",
            "\n",
            "@nseyram @Citi @eastsportsman It's funny..my house is a stones throw from the market..nowhere will u get 3-5cedis \n",
            "\n",
            "============================== Similar Text: 4 || Euclidean Distance: 4.533 ============================== \n",
            "\n",
            "@thisladysview Christian? How about mentioning the people who have lost their lives?  #Covid_19 Shallow human being. \n",
            "\n",
            "============================== Similar Text: 5 || Euclidean Distance: 4.558 ============================== \n",
            "\n",
            "RT @tedlieu: Dear @realDonaldTrump\n",
            "\n",
            "THINGS NOT SUPPORTED BY DATA:\n",
            "-Injecting bleach in people\n",
            "-Shining light in people\n",
            "-Hydroxychloroquine… \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-h-guNn29Sz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def find_nearest_n(train_matrix, train_indices, test_matrix, test_indices, test_set_df, df_tweets, n=5):\n",
        "    similar_texts_list = []\n",
        "    euclidean_distances_list = []\n",
        "    euclidean_nearest_distance_list = []   \n",
        "    similar_themes_list = []\n",
        "    similar_top_themes_list = []\n",
        "    for vector in test_matrix:\n",
        "        euclidean_distance = distance.cdist(vector.reshape(1, -1), train_vectors, 'euclidean').flatten()\n",
        "        nearest_doc_indices =  euclidean_distance.argsort()[:n]        \n",
        "        top_tweet_Indices = train_indices[nearest_doc_indices]\n",
        "        \n",
        "        similar_texts = [text for text in df_tweets.loc[top_tweet_Indices, \"Text\"]]\n",
        "        similar_texts_list.append(similar_texts)\n",
        "        \n",
        "        euclidean_distances = [np.round(score, 3) for score in euclidean_distance[nearest_doc_indices]]\n",
        "        euclidean_distances_list.append(euclidean_distances)\n",
        "        euclidean_nearest_distance_list.append(euclidean_distances[0])\n",
        "                                                                   \n",
        "        similar_themes = [theme for theme in df_tweets.loc[top_tweet_Indices, \"Theme\"]]\n",
        "        similar_themes_list.append(similar_themes)\n",
        "        \n",
        "        top_similar_theme = max(set(similar_themes), key=lambda x: similar_themes.count(x))\n",
        "        similar_top_themes_list.append(top_similar_theme)\n",
        "    \n",
        "    df = test_set_df.copy() \n",
        "    df[\"original_theme\"] = df_tweets.loc[test_indices, \"Theme\"]\n",
        "    df[\"similar_texts\"] = similar_texts_list\n",
        "    df[\"euclidean_distances\"] = euclidean_distances_list  \n",
        "    df[\"nearest_euclidean_distance\"] = euclidean_nearest_distance_list\n",
        "    df[\"similar_themes\"] = similar_themes_list\n",
        "    df[\"top_similar_themes\"] = similar_top_themes_list\n",
        "    return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSgc4xkeRV5C",
        "colab_type": "code",
        "outputId": "79c2be05-f8c2-4ad4-d623-a562c589672f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "nearest_test_df = find_nearest_n(train_vectors, train_indices, test_vectors, test_indices, test_set, df_tweets, n=10)\n",
        "nearest_test_df.head()"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>original_theme</th>\n",
              "      <th>similar_texts</th>\n",
              "      <th>euclidean_distances</th>\n",
              "      <th>nearest_euclidean_distance</th>\n",
              "      <th>similar_themes</th>\n",
              "      <th>top_similar_themes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4648</th>\n",
              "      <td>catnip coffee you dont have to give me a new ...</td>\n",
              "      <td>coffee</td>\n",
              "      <td>[RT @claylongs: Jerking off in the car up on m...</td>\n",
              "      <td>[5.294, 5.377, 5.568, 5.57, 5.62, 5.63, 5.643,...</td>\n",
              "      <td>5.294</td>\n",
              "      <td>[car, cake, cake, cake, cake, car, cake, car, ...</td>\n",
              "      <td>cake</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>362</th>\n",
              "      <td>candicontreras7 hello thank you for tweeting ...</td>\n",
              "      <td>Bank/Financial</td>\n",
              "      <td>[@JTrey3 Hello, thank you for tweeting us. So ...</td>\n",
              "      <td>[1.345, 1.382, 1.505, 1.547, 1.812, 1.855, 2.3...</td>\n",
              "      <td>1.345</td>\n",
              "      <td>[Bank/Financial, Bank/Financial, Bank/Financia...</td>\n",
              "      <td>Bank/Financial</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4645</th>\n",
              "      <td>teekhi mirchh harriisqureshi lemme healuh maj...</td>\n",
              "      <td>coffee</td>\n",
              "      <td>[RT @guu_tara: doodle  ZERO(ver.metless) https...</td>\n",
              "      <td>[5.308, 5.533, 5.619, 5.634, 5.636, 5.735, 5.7...</td>\n",
              "      <td>5.308</td>\n",
              "      <td>[car, tokyo, ramadan, nasa, dog, coffee, cake,...</td>\n",
              "      <td>ramadan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2086</th>\n",
              "      <td>rt trumpwarroom are you kidding me michigan de...</td>\n",
              "      <td>covid-19</td>\n",
              "      <td>[RT @JCAPoquoson: Punished for telling the tru...</td>\n",
              "      <td>[5.715, 5.862, 5.976, 6.136, 6.151, 6.167, 6.1...</td>\n",
              "      <td>5.715</td>\n",
              "      <td>[covid-19, covid-19, nasa, dog, covid-19, rama...</td>\n",
              "      <td>covid-19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2988</th>\n",
              "      <td>state rep whitsett nearly died from coronaviru...</td>\n",
              "      <td>covid-19</td>\n",
              "      <td>[RT @GOPChairwoman: State Rep. Whitsett nearly...</td>\n",
              "      <td>[6.137, 6.513, 6.519, 6.604, 6.619, 6.647, 6.6...</td>\n",
              "      <td>6.137</td>\n",
              "      <td>[covid-19, covid-19, dog, dog, @Citi, airlines...</td>\n",
              "      <td>dog</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   text  ... top_similar_themes\n",
              "4648   catnip coffee you dont have to give me a new ...  ...               cake\n",
              "362    candicontreras7 hello thank you for tweeting ...  ...     Bank/Financial\n",
              "4645   teekhi mirchh harriisqureshi lemme healuh maj...  ...            ramadan\n",
              "2086  rt trumpwarroom are you kidding me michigan de...  ...           covid-19\n",
              "2988  state rep whitsett nearly died from coronaviru...  ...                dog\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I19THYGZRoi3",
        "colab_type": "code",
        "outputId": "ba3c3957-b251-4363-cb8b-8485803876c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "accuracy = 100 * np.sum(nearest_test_df[\"original_theme\"] == nearest_test_df[\"top_similar_themes\"])/nearest_test_df.shape[0]\n",
        "print(\"Accuracy on test data in predicting theme: {}%\".format(np.round(accuracy,2)))"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy on test data in predicting theme: 72.73%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vc9m2POaR5mN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nearest_test_df.to_csv(\"BERT_nearest_test_tweets.csv\")\n",
        "! cp -r ./BERT_nearest_test_tweets.csv './drive/My Drive/MIDS/docSimilarity/model_save/'"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}